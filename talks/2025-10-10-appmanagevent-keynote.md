---
title: "AI and the future of enterprise apps"
date: "2025-10-10"
event: AppManagEvent 2025
location: Utrecht, Netherlands
audience: App management and EUC practitioners
format: Closing keynote with slides
recording: https://www.youtube.com/watch?v=XoJ5uL1op_E
authority_level: 5
file_type: talk
tags: [post-application-era, ai-agents, computer-using-agents, workspace-as-control-plane, citizen-development, app-management, osworld-benchmarks, citrix, ai-productivity-platforms, capabilities-orchestration, vdi]
staleness_threshold: stable
---

# AppManagEvent 2025 - October 10

## Talk details

**Title:** AI and the future of enterprise apps

**Abstract:** The concept of applications is dissolving. Brian traces how AI platforms are becoming the primary gateway to work for knowledge workers—connecting to modern apps via APIs, operating web apps through browsers, driving legacy desktops through computer-using agents, and increasingly skipping applications entirely by manipulating files directly. Argues that app management must evolve into capabilities orchestration, and introduces the post-application realization: if AI can edit Excel files directly, do we need Excel at all?

> **Note:** This transcript was machine-generated from a YouTube video and may contain errors including misheard words, incorrect names, and inaccurate technical terms. Please refer to the [original video](https://www.youtube.com/watch?v=XoJ5uL1op_E) before quoting.

## Transcript

Hi everyone. My name is Brian. Thank you for being here today. Thanks to Coert and all the organizers. I have the privilege of delivering our final talk of the day—sitting in between you and beer, so the best place to be. My talk is about AI and the future of enterprise applications. In my day job I'm a futurist at Citrix, but this talk is not about Citrix specifically. It's about the industry and end user computing in general. What you need to know about me is I've been doing end user computing for 31 years. I've been through a few cycles and a few hype bubbles, and so for today, my purpose is just to tell you based on my experience how I see the next five years evolving, and obviously a big part of that is based on artificial intelligence.

When I look at artificial intelligence and the future of enterprise applications, I see a lot of headlines like "Companies are pouring billions into AI, yet it has yet to pay off." Nearly 8 in 10 companies report using generative AI, yet just as many report no significant bottom line impact. Or there's this study—a MIT report that says 95% of generative AI pilots at companies are failing. This report is highly discredited because of a small sample size and confusing questions, but that doesn't stop people from putting it everywhere. And honestly, it's useful for presentations like mine because it drives the narrative that there's not a lot of return on investment for AI, especially when you have corporate-mandated AI or AI that's being led by IT departments.

What is corporate-mandated AI? It's that $500,000 AI-powered service desk that took six months to implement and still can't reset passwords consistently. It's the enterprise security AI tool that generates 10,000 false alerts per day that no one investigates. It's that predictive analytics infrastructure suite that needs a data scientist to tell you that servers fail when they're old. It's the AI assistant for customers that still cannot reliably answer "How do I make an appointment?" And meanwhile you're secretly worried that your chatbot is about to go viral—and I don't mean in the good way.

So when I think about AI in the enterprise and read these headlines around AI investments, it's clear we're just throwing things out there. We need a chatbot, or we need an LLM, or we need to customize something. IT departments are trying to build AI for customer support and HR. I don't blame them—we all need an AI strategy, right? The CEO says we need an AI strategy, and it rolls down to the CIO and the CISO. Everyone is trying to avoid being the Blockbuster Video in the Netflix story. No one wants to be the company that missed the turn or missed the bubble, but it's hard to know exactly what's happening. When corporations invest in AI, it's slow. It's the traditional way they do projects. But to me, this is missing the point entirely.

I've spent 31 years working on end user computing, and the users are the part that matters. It's where the people are. What's interesting in the enterprise to me is not the backend stuff—it's what regular human workers are doing. All of us are using ChatGPT. We're using Claude. We're using Gemini. We're using these tools every single day, right? Co-pilots, Mistral, whatever you're going to be using—all of the workers in their jobs and outside their jobs are using these AI tools. And what are they using them to do? Well, we're chatting with them by typing back and forth, or maybe chatting via voice by talking and listening. We're asking them to brainstorm with us, analyze data and documents, help us write papers and TPS reports and emails. We're using them to help us create business strategy, ask for personal life advice and career advice. We're using them to generate images, materials, and videos now.

Gosh, where else are we going? There's an AI browser war apparently right now, because every web browser manufacturer now has an AI engine bolted onto the side. They're sitting on our shoulder watching what we do with the web. Chrome has Gemini, Edge has Copilot, there's Dia, the new browser company—I think Perplexity is buying maybe, or automatic is buying Dia. See, it's crazy right now with all these browser tools. We have a new browser war with AI engines bolted onto the browser to help us browse the web. I look at what all these tools are doing and I say what's next? Co-browsing, I guess, is the next feature. But really I call these things chatbots—but are these chatbots? If you go into Claude there's a connectors button. Click that and look at all the things you can connect it to for existing applications. Enter your API key or your OAuth or your password information and look at how big the scroll bar is. There's all these connectors built into Claude today. There are connectors that can connect into desktop applications, so Claude can actually control and interact with the applications running on your desktop. In fact, if you don't see an application on the list, you can add your own custom connector by giving it an MCP endpoint, your settings, and your tokens.

ChatGPT just a few days ago introduced apps that plug right into the ChatGPT environment. So referring to these tools as chatbots is not really the right word anymore because they do so much more than just chatting. What do you call these things? AI productivity platforms? Agent platforms? AIOS? Whatever we call them, these tools are becoming the gateway to work for human knowledge workers. The human knowledge workers are making these AI platforms their gateway to work. How are workers interacting with them? We're talking to them via text or voice. These tools are observing the screen, watching our applications, generating video, generating audio. There are all different ways I can interact with these platforms. These platforms themselves are web apps, Windows and Mac native apps, iOS apps, Android apps. They're multimodal. Wherever I'm using whatever devices I'm using, these AI platforms exist there. So all of us humans are really going to these AI platforms as our main interface into work, with the idea that these platforms can then talk to the other applications we need.

Just like I showed you in Claude or ChatGPT where it can plug into modern connectors—SaaS applications, anything with an API or an MCP server. The workers are talking to the AI platforms, and the AI platforms can connect into OneDrive and Google Drive and email and calendar and spreadsheets. I can ask questions and get data and that sort of thing. That's great. But not all applications have APIs and modern SaaS interfaces. What about apps that don't have those connectors? If I have an old web app without a fancy new interface—well, look at this. ChatGPT just announced agent bridging research and action. We saw all these web browsers now have an AI engine bolted onto the side, so AI is watching our browser. As I browse the web and talk to my AI, I'm browsing, talking, browsing, talking. At some point I'm like, "Yo dudes, YouTube just can't do this without me." And that's what we're seeing right now. AI is moving from watching your browser to operating your browser. This is exactly what ChatGPT agent is. This is a real thing. You may have seen demos of this. The demos are super lame because you just see a video of the cursor moving, typing, navigating a web page. You don't even know if it's an AI doing it versus your mom. But the AI now can absolutely operate your browser and move the mouse and click around and do things. That's ChatGPT agent. Claude has these. All the platforms are building these things.

So if AI is operating my browser, that means as human workers I'm talking to my AI platform. The AI platform is connecting to modern applications via APIs or MCP. If it doesn't have a modern application interface, that's great—it has a web browser interface. So the AI can operate the web browser for me. Okay, what about the apps that don't have connectors and don't have web interfaces? How do I deal with those applications? Well, we have computer-using agents now. Any app that's not a web app and not a modern app—like a Windows desktop app, MSIX, or App-V—that's the next step. Every major AI company is building these computer-using agents that can actually process a computer screen, observe the screen, operate the mouse, operate the keyboard, and manage their way through the desktop. This is something that is real today.

How good are these agents? There are benchmarks for this. There's an open-source benchmark called OSWorld that runs on Linux, Mac, and Windows. It's a basket of 369 tasks described in regular human English. One task is "go on the desktop, grab the spreadsheet, open it here, total the results on the second tab, and email it to Tim." There are 368 other tasks like that—changing backgrounds, operating files, downloading, zipping, moving things around. This benchmark came out in April 2024, 18 months ago. They had humans operate this benchmark and humans get about 72%. So that's the average worker. Most people get confused at things, but 72% is kind of our benchmark. At that time, AI agents scored 12%. Everyone said "Oh, they're never going to be able to do this. It gets complicated." Well, 18 months later in August we're at 61%. In October we're at 70%. As of last week we're at 70%—and that sound you just made is the correct response. What happens when these things are as good as humans? What happens when they're better? What happens when they score 100%? It's interesting because this benchmark is just testing the AI's ability to use the computer. It doesn't know what to do on the computer. It's not writing your emails or doing your business analysis. It assumes the AI can use a computer well enough that I can say "Grab the sheet, do this, copy this, open Workday," and it knows how to navigate and do those things. So we've got computer-using agents that are a thing. These are always getting faster. One downside today is they're kind of slow. They take a screenshot, analyze it, predict a movement or action, then take another screenshot and do that again. It's like dragging a puzzle piece and timing how fast you can do it because the agent is going to be really slow. But remember self-driving cars in 2005? It was slow, crawl, stop, slow, crawl. As technology evolves, these are going to get faster. There are now specialized models instead of general models that classify every image in the universe. These are made to understand screenshots and pick out navigation elements and make path planning for how to click and navigate. What's nice is they can process a full HD screen in less than 30 milliseconds, which means it can do it in real time at 30 frames a second or more. So we're getting to the point where AI's ability to operate a screen approaching real time is on the horizon.

Going back to the diagram, I've got my workers using the AI platform. The AI platform is plugging into modern apps via APIs or MCP. If it doesn't have a modern application interface, it's got a web browser interface so the AI can operate the web browser. Now that takes care of all of that. What about the apps that don't have connectors and don't have web interfaces? We have computer-using agents. So the AI platform is able to access all three types of apps—modern apps, web apps, and legacy apps—via different technologies. I kind of draw a line here to separate the personal from the corporate side of things. Where exactly this line goes and which counts as personal and what's work is going to be different for everyone. But I draw that line because there is a separation between us as workers with our personal AI and what we need that AI to do at work.

Most of us use ChatGPT and we feel confident with it. We paid for a subscription. We've got the security set so it doesn't learn on our models. We tell it everything. Maybe I'll tell a crazy work story like "I was just asked to do this and I don't understand it at all. What should I do here?" which I might not put into work-controlled AI, but I'll do on my personal one. It's like with our personal devices—when you have a personal cell phone, you feel more confident with all your texts and images on there. But if it's a work-owned phone, you want to keep it more separated. It's the same idea for AI. We're using ChatGPT or Claude or multiple ones we choose, and we're telling it everything. We have no shame. We use it for everything. But when it comes time to doing the work side of things, we want to take a more measured approach.

I don't envision the future where work is giving you the chatbot that's your primary chatbot in everyday life. It's like with devices—work-owned laptops versus personal, work-owned phones versus personal. I can envision work gives you a chatbot and maybe that chatbot talks to your personal chatbot. So we've got like the work persona and the personal persona. But I don't necessarily envision the company's going to hand you a chatbot and you're going to use that for everything in your world. There will be some separation there.

The reason I mention this separation between personal and work is because if you think about managing end user computing—how we manage users and Windows and VDI and applications—in this sense, it doesn't change too much. If I'm thinking about things from a company standpoint, I'm managing modern apps and APIs. I'm managing web applications. I'm managing existing Windows applications. This is the way I've managed the workspace for the past 20 years or so.

What is a workspace? It's your apps and their data. Regardless of whether it's a web app or Windows app or SaaS, I've got applications and data. That's part of my workspace. I have the identity of the person doing the work—usually me with my login ID. I have my security boundaries, my permissions, and the boundaries of the work I'm doing. I have the context—what am I trying to do with which files, which applications and data do I need, and what goal am I trying to achieve. So apps, data, identity, security, context—all this together equals the workspace. Of course the workspace itself doesn't do anything unless you attach a worker to it. For the past, well forever in IT, the worker has been a human worker. Now that we have AI, we're seeing that worker could be an AI worker or a human worker or an AI and a human worker together. So from the standpoint of IT, it doesn't change too fundamentally. A worker is connected to my workspace doing work with identity and context and security and boundaries.

I don't even know if I necessarily care if that worker is a human worker or an AI worker. People worry about ChatGPT operating a mouse and computer. They worry about the things that large language models might do—hallucinating, being biased, accidentally deleting everything. Fair questions, but you can say the same thing for humans. Humans can be biased. Humans can delete things. Humans can make mistakes. So we have guardrails to protect us from humans. We can have guardrails to protect our environments from AI as well.

But AI doesn't change that much about how we think about managing a workspace and who my workers are. AI has impact, but the impact is not fundamentally about workers because if I think about my workspace as I said, it could be a Windows machine, it could be a web browser, it could be a mobile device. Your individual workers will be connected to multiple workspaces at the same time. I'm logged into my laptop, I'm logged into my phone. The same can be true for my AI platform. As a worker, I log into my AI platform. The AI platform itself logs into my workspace and does work on my behalf—maybe SaaS applications directly, computer-using agents, browsers, whatever. When the user goes home and closes the lid on their laptop, their local devices disappear. The AI is no longer able to access that unless the workspace is also reflected back in the cloud somewhere and then the AI can continue. I was pretty sure I was in Den Bosch at a VMUG meeting in the Netherlands last year and I declared the year of VDI as kind of a joke. But I kind of joked that the year we're in now is the year of VDI because now that AI can use computers and navigate desktops, I actually have a reason for every single worker to have a VDI desktop. Maybe I didn't need a VDI desktop myself before—I could do everything I needed on my laptop. But if I want AI to log on as me and work when I'm not working, then yeah, log into the cloud and once I log off you can continue. So the idea of building our workspace and making it accessible from anywhere at any time—all these things we've been trying to do for decades—now actually has a secondary use case because these AIs can access that workspace.

The reason I mentioned this at the start is because I don't believe IT-led AI is really where the innovation is happening and I don't mean this in a negative way. Applications that have AI capabilities are the latest and greatest technology. Yes, every application you buy today has Copilot functionality or machine learning algorithms or some kind of AI built into the product. But that's not fundamentally changing the way work happens. It's just the latest technology. Ten years ago every app also had a mobile app. Twenty years ago every app also had a web application. So AI inside applications we're buying is not fundamentally changing the way work is happening. It's the individual workers who are bringing in these AI platforms and using them within their jobs. That's where AI change is really impacting companies.

I like this idea and I like thinking about an AI worker and a human worker in the same way and the reason I like thinking about them using the same workspace is because that's the easiest way to actually integrate AI with your company in a way that impacts things. When your AI agents use the same platform as your human workers, it's very simple for continuity and ease of implementation. The AI platforms can gradually have more and more access to your applications. You can try them with one application here or one application there using your existing applications and processes. Any worker who's not sure how they work can see these things operating. They can watch a session recording video of what it did. They can see the outputs and the applications it's opening and closing. This also allows individual workers to experiment and test and say "I wonder if AI can do this or I wonder if it can do that." And it allows us as a company to use all of our existing security, our management tools, our auditing, our updating, our training processes—everything that we built as an IT department, we don't have to throw away. We're not building a brand new platform from scratch. All of the applications and processes and workspace and security that we use with all our workers today that are humans will also apply to our AI workforce.

Everything you do—application updates, the way you train both your end users and your admins, the way you monitor your environment, the way you manage change and updates, how your help desk operates, troubleshooting, how you audit, environment optimization—all of that. If AI is using the same system that your human workers are using today, all of that ends up being the same. My belief is that this is the way AI is going to enter the enterprise—as individual workers. You think about all your workers within the organization and we think of them as personas or profiles with different application sets, different devices they use, different VM sizes and work patterns. They're all going to use AI in their own ways as well. AI is very personal to people. Some people love ChatGPT. Some people like Claude. Some people build custom GPTs and custom system prompts. Some people do not. Just like people use different laptops and phones and use things differently, the same is true with AI. All of the workers in their own capacity are going to start using their own AI tools. As they use those more and more, they will expect those tools to be able to access their work applications regardless of the technology—whether it's SaaS, desktop, web, or whatever that works out to be.

So we go back to this workspace and now the workspace has two workers attaching to it, right? I've got my human workers and I have my AI workers, and both of these worker types are using this same workspace. The way I've drawn it I really do think of human workers and AI workers, but more recently I've started to evolve the thinking a little bit. Maybe it's not either/or. It's not a human connecting or an AI connecting. I think over time it's going to change the order. The AI platform ends up sort of sitting in the middle. So the human workers are increasingly just working with their AI platforms and then the AI platform itself, if it needs something from a backend application or data source, it's going to talk to that data source. I've got kind of two interface points—my applications to the AI and then the AI to my humans.

How are humans actually using the AI? I think the user interface can be really whatever the human wants. This is really critical because it could be a keyboard, a mouse, a laptop. The way we interact with AI today, there's a lot of typing—we're typing to it and it's typing back and showing things in the canvas. It could be voice chat, though. It could be voice chat through earbuds as I'm walking down the street, or it could be voice chat with an actual avatar where it's deep-faking a virtual coworker that is the pixel embodiment of the AI. And again, this is the same AI, right? Like ChatGPT I'm talking to in my ear until I get back to my desk and then I'm typing to it. Maybe the interface is earbuds while mobile, maybe it's casting that interface to whatever device I have—phone screen, goggles, whatever. That's what the user interface is.

People ask about meta glasses and if that's the future of interfaces. I mean there's a use case where having glasses and words floating in front of you might be something you want, but that doesn't replace screens. I think we're still going to have time where we want to type and sit at a screen with a keyboard and visualize what I'm doing. But I don't think when we do that we're using a traditional application. I think the application is my AI environment. If I need a spreadsheet, it's going to draw the cells I need on demand for me on whatever device I happen to be using. I can zoom in and zoom out and just tell it or roll the mouse and it will redraw at a different size. So the actual user interface is being generated by the AI platform on demand in whatever format the worker wants at that time.

Now if I look at the interface between the workspace and AI platform, this also can be lots of different mechanisms—whatever makes sense. Maybe the AI platform is pixel scraping if it has to connect to an old legacy Windows workspace and I don't have a modern interface. Just do it like the way we use HDX or RDP today. The consumption end is not your human worker anymore. The consumption end is an AI bot just reading the HDX protocol and looking at the screen primitives and understanding what the screen is. Maybe it's sending Windows primitives down. Maybe it's controlling the web browser. Some of these ones use web browsers and script the pixels off the browsers. Others just access the DOM directly, right? Like why do I need a web browser to render a web page into pixels for humans to see and then the AI is going to take those pixels and deconstruct them back into logic? Just give me the source code of the website and all the JavaScript code and let the AI handle it in a way that makes most sense. It can pixel-scrape if it needs to. It can access the DOM or web stuff directly. It might be using modern APIs if it's modern applications.

So the user interface here over time starts to evolve because I could look at this as a user interface for humans whereas this is the user interface for AIs. AIs are going to need API interfaces. Humans are going to need voice or text or some kind of pixels. This is where we're going—everything out of my workspace is no longer built for humans. Everything out of my workspace is built for AIs to consume, and then the AIs, if there is a human interface needed, will generate that human interface.

I think this is where we're going. There's going to be a transition period though because we're going to be in this kind of half-way state, like a car that looks like a carriage, right? Because that's what shaped things were when motors came out. So we're going to be in this transition period where we're kind of half in and half out, and that sounds awful, but it's also like really good job security for us. I joked with Tim about the uncertainty of half transitioning and how it's really good for all of our careers.

Let me use an example from the 1990s. When Windows applications were stuck in the office before Citrix, you had Windows apps and a desktop and a LAN. Then mid-90s the web was announced and remember, the web was going to kill Windows because the web was the future, right? Why? I could access an app instantly from any device without having to install it first. I could access it from any device—not just Windows but Mac or Linux. I could access my apps from anywhere, not just in the office. With web apps, I could update once on the server and everyone just refreshes and they got the latest version. I had good application performance over slow connections. I had better security because no data was stored on the endpoints. These were the advantages of why Windows was going to be dead and web apps are better. How do I get this? It's simple. All you have to do is rewrite all your applications from scratch. No problem. So Windows is still a thing 25 years later because this is theoretically a better, cleaner solution. But corporations don't do the best, cleanest, theoretical best things. They do what works. If you have current applications and they're operating fine and you've got 30 years of development and all the edge cases—sure, it's maybe theoretically not the best way, but why change? Corporations still use Windows and that's why Citrix exists in the first place. Citrix said instead of rewriting all your apps, what if we could give you all these advantages but not have to rewrite all your apps? So 1990s—why Citrix was the future. And now instead of just rewriting all your apps from scratch, just use Citrix and you're done.

Of course Citrix started in the 90s, now you've got VDI, remote desktop, all those ecosystems. But the point was this was a crazy hack. I remember when I first learned about Citrix in the mid-1990s, I didn't really want to dedicate my career to it because obviously Windows is dead. Everything's going to be web someday. And I was like, "Well, I guess I'll do the Citrix thing as a transition, get us through Y2K, and then we can finally kill Windows and be done with this thing." But it turns out this was actually fine, right? We use Citrix as a modernization wrapper to take existing applications that have modern needs and we use that as middleware to add these modern needs to our existing applications. That same concept is what's going to happen in this next phase moving forward as well.

If I go back to the drawing from before where I said the human interface is sitting between the AI and the humans, the backend workspace doesn't need to have a human interface. It only needs an interface for AI. But I think this is something that's going to be temporary because for now we're going to have both, right? This image is more appropriate for today where my human workers act on there's a human UI to my applications directly. There's also a human UI to my AI platform and then the AI platform is, as you've seen more and more, getting plugins for direct modern applications, browser control, etc. I feel like this is actually pretty close to what we're using today.

And then I look at these AI platforms and if I think about them as using existing human interfaces—well, that's great, they can use the human UI also. If I think about personifying the AI into some kind of human-like thing that's able to access these human interfaces—I mentioned AI can use a browser, AI can control your computer, so it's using the human interface, just as the AI. So I could really draw another purple arrow here where a human UI is being consumed by AI, human UI is being consumed by the humans, the humans are using that human UI for the AI and the actual backend applications themselves. But this is a very temporary thing because it's kind of funny. We have to make this work in this transition period because not every application has an AI interface and not every application or workplace environment has AI that's good enough to do everything yet. So we have to build these human-style interfaces like computer-using and browser-using as a temporary workaround to get us where we need to be.

We have a catch-22—I need to have these human workarounds temporarily so that my AI can remove the need for human elements on these things. But we make these things look like humans because that's where everything is today. You know we talk about why humanoid robots use the same form factor as humans? It's because we live in a human world. If you want a robot that can do anything a human can do, make it about 2 meters tall and 100 kg with an 8-hour battery life and have it arms and fingers. Now I don't need a specialized robot. If I want this robot to drill, I have a drill. If I want to iron, I have an iron. If I want to vacuum, I have a vacuum. So I allow the robot to use all the tools I already have, and now it can do everything I need in my environment.

Taking this back to the enterprise environment, it's the same kind of thing. All these workers today are dealing with the AI platforms directly and asking questions and brainstorming and all that. But when I need it to do something on my behalf, it probably is going to have the best chance of using my existing tools that I already have today—my desktops, my logins, my authentication, moving my mouse, seeing my applications, operating the browser, logging on as me, doing all these kinds of things.

So for today that means from the IT standpoint it doesn't change too much the way we think about things. I'm still managing apps. I've got modern apps that I subscribe to. I've got web apps that I'm managing myself and I've got desktop and legacy applications in Windows environments that I'm managing. So it doesn't change too much. These apps are being used by a human or an AI but it doesn't make too much of a difference. I understand the apps. I understand the humans. There's this weird thing though—the AI platform itself. How do I hold that? AI is an application, I guess. If I'm managing applications, ChatGPT is like just another application. It runs somewhere. It has access to data. It's got updates and security holes and CVEs and I have to manage it and manage access.

But it's also a consumer of my applications. So the AI is sort of a weird hybrid—it's part app and part end user. When I think about how I manage that from an IT standpoint, it's a little bit blurry. The reason I mention that is because what's so interesting here is the AI platforms have the ability to generate new applications and they can generate them very quickly. They can be very dirty and ephemeral and you don't even know that it happened.

As an example, I could say "Hey AI, get the spreadsheet from OneDrive and update the latest numbers." I've told my AI to do something, and that AI is going to go do it, right? It's got 70% computer-using ability. Next month it'll be 80%. It can use a browser. A lot of these models are series of models—one model that takes your task, plans out whether I need to write a Python app for this or connect in here or do that. So when I ask the AI to do this, I'm not directing the AI specifically. Maybe in the early days I might say go to this file location, find this folder. It's like when you have a new employee who doesn't exactly know everything, you're more specific. But as they learn more you can just say "Oh, get the TPS report and update it" and they know where it's saved and what you mean.

We're going to see the same thing with AI. What's interesting is if I look at my humans and I ask the AI "Hey, update that OneDrive report and send it to Tim," the AI is going to do that. How's the AI doing that in the back end? I don't care as the worker. It doesn't matter to me if the AI needs access to my desktop to complete it—go right ahead, you know how to access my desktop. If it needs a browser, if it can do it directly, I don't want to be in the business as a regular worker of micromanaging the AI and telling it every single little step to do.

There's a lot today where AI works because the AI isn't good at figuring out things on its own. You see a lot of examples of various application environments similar to robotic process automation where you're training an AI. You're showing the AI: do this, then do this, then do this. You're holding the hand of the AI showing it how to do things. That's fine if you have repeatable tasks. But most of what we do in knowledge worker land is not repeatable tasks. If a task was that repeatable, I probably would already be using an RPA package for the past decade. So the idea that in order for AI to be good for knowledge workers I have to train my knowledge workers on how to train the AI and have them step through step by step—absolutely not. That is not happening. The workers today who are more advanced and nerdy are going to do that. But your regular rank and file workers are not going to be training their AIs on how to do things. The AIs will get better at figuring out how to do things essentially on their own. And then knowledge workers are just going to ask the AI to do whatever it has to do, and the AI is going to figure out the right way to do it and do it.

Now the question is when this happens, is that an app? How do you define an app? These things I'm asking the AI to do—I should point out we saw just last week, a couple weeks ago, ChatGPT Pulse is basically ChatGPT doing this on its own too. The ChatGPT environment watches what you do. It watches what you ask for. It watches what you query and it's going to start basically building a feed based on what it thinks you might need. This is a feature that's deployed today. It exists today. It has a feed now inside your ChatGPT environment generated by ChatGPT based on what it thinks you might need. If it has access to your calendar, it'll pull your calendar in. It'll tell you when you should leave, all these things, similar to how Office Copilot in Outlook can look at your calendar. Imagine that across all your applications—and that's real today. That's built into the product today.

So these environments, whether it's something you're asking for or something the environment just builds on its own, it's almost like it's creating its own applications. That's what I say like, you know, we're here at an app management conference. I used to think when I was doing Citrix projects back in the old days, it was always like a 10-to-1 ratio of users to apps. If I had 5,000 employees, there's probably 500 apps. But now with the ability for AI to just do things, the numbers might invert. It might not be 10 users per app. It could be 10 apps per user. Because now every single employee, every single worker you have becomes an accidental citizen developer. This is not vibe coding, right? Vibe coding is fun and it's something computer nerds do when they want to write a new application. This is stuff that like our moms would do. They're saying "Hey ChatGPT, do my expense report. My photos, you know, are in the receipts from my trip to Utrecht. Check my email and let me know if you need anything" and it goes and does their expenses every Monday and now they have an app that's running and they haven't even thought about whether it's an app. But is it an app? They're different than regular apps—they're ephemeral. Maybe this app only exists for a few seconds, maybe it exists for a week, maybe it only runs for a few seconds but runs every week. Maybe workers start trading them with each other. These apps might be long-lasting or disappear but they don't have the life cycle of traditional apps. They're undocumented. Like they're documented in the sense that you can look at the prompt history of what the worker was asking for. But what's the app doing? What security protocols are in place? How's it handling the data? Who knows? These apps are highly interconnected and tangled. This one's talking to this website and going over here and finding this API and doing this desktop thing. Who's talking to who? What are the dependencies? What version of Claude is it? Does it work on your enterprise account or your personal account? Who knows? These applications are constantly evolving and never static. Even if you have the same prompt running every week, ChatGPT might have version upgrades and that prompt generates new code. Actually, even if ChatGPT doesn't change, the prompt generates new code. Maybe one time it's running in Python and the next time it's running in Rust. Why did it pick that? I don't know. But that's what's there. These apps are invisible also—you don't really know about them. It's like dark matter. There's circumstantial evidence that apps exist because things are being done that workers asked for, but I don't really know who, what, why, when, where, how exactly it's happening.

This is madness. This is not shadow IT. People talk about shadow AI or shadow IT and shadow IT is like the dark side, assuming there's a light side of this stuff happening above board. I call this more like alternate universe IT. This is just crazy town. This has no relation to the way that IT and app management works today.

And it gets even crazier. Last week—well, a month ago or so, Claude announced something. And then just last week, Microsoft announced Vibe Mode—introducing agent mode in Office Agent in Microsoft 365 Copilot. Claude can now create and edit files. Has anyone used this or seen this? You all know the first time you used Copilot in Microsoft Excel and we were very sad because you knew what you wanted it to do and you knew what it could do and there's a big delta there. But we thought well, Excel is important and Excel as an application is always going to be around. Copilot is going to get better and let me interact with Excel in new ways. And then it turns out Excel files are just XML that anything can read. So Anthropic trained Claude on all the Excel files on the internet and guess what? It now talks Excel directly. It's like the protocol droid with three million languages, right? It can just write Excel files. So you don't need Excel anymore. You just drop your Excel file into Claude, ask it what's on the third tab, and it draws the third tab for you right there on the side of the AI app. I can ask it to do this—build a new spreadsheet. I don't even have to start with a spreadsheet. I say "Just build me a spreadsheet that does this, this, this. I want this. I want this. Here's the data." And it's just working. When you're done you're like "Oh, give me the file by the way" and out pops an Excel file. Same with Word, all these things.

So it turns out the application only exists to manipulate the data and the files. If the AI has true enough understanding of the applications, the data, and the files, I don't need the actual application portion of this. So even the concept of apps starts to go away, which is really crazy and also not that far off. To me the takeaway for this is how do you deal with this? Fundamentally you've got to manage the working environment. You can't manage the apps. For example, you cannot vet 10,000 applications—every new app that is created that might only exist for a few seconds. The way you approve and determine if apps are okay and certify them, you cannot do that anymore. You cannot vet 10,000 applications. But you can secure the workspace where they operate. Maybe I don't care specifically what this application does. I just make sure it has a secure working environment with boundaries and guardrails and the proper audits so it can kind of go nuts within its little protected environment.

In the future you cannot document every workflow, but you can monitor and record what's happening in these environments. You cannot approve every single automation, but you can control what data and what systems these automations can access. You cannot train workers on every single app, but you can provide guardrails to allow the workers and the apps they create to work in safe environments. It's changing our thinking from managing, securing, monitoring, observing apps. We're taking a step back and looking at the workspace, the working environment, the environment where these applications and AIs are operating. That's what we manage and that's where we focus.

I break this into near-term and far-term changes to our thinking. For the near-term changes, number one, we have to accept that there are these new economics of applications. When creating an app costs less than the meeting to discuss creating it, everything changes. We have that now. If you're doing vibe coding and you can spend a day building a pretty functional application, sure, a lot of professional developers say the code is garbage and not secure. Yeah, people don't care. We've bought a lot of commercial products that were garbage code and not secure. Our users are certainly not going to care. But it's interesting because apps have an economic life cycle—you spend time investing, planning, mapping, writing code, testing. It's a lot of front-loaded work. But with AI code generation that's free, the value is no longer in the code. The whole way we think about economics of an application is going away. This means we have to redefine what an application even is. We have to shift from application-level to environment-level security—securing the environment, not the individual applications.

We need radical observability. I don't love this, but it's the best we have. You hear about how AI does crazy things every once in a while. So just put very tight guardrails, maybe turn on session recording, maybe use other AI to analyze the session recordings and timestamps and compare things. But for now we need to have like a short leash on the AI with guardrails around what it can do, and we need to be running this in environments that are strictly observed. This might be an instance running on a secure lockdown VDI container or something versus your random laptop where you turn around for a second and it's bought everything on Amazon.

We need a supported path for citizen development. I'm not talking about workers vibe coding. I mean workers are just asking the AI to do things. As soon as it has access to Google Docs and OneDrive and the calendar, they're going to say "Oh, do this, do this, do this." What if it doesn't work? What do they need to know about that? We need to understand that citizen development is not going to be our nerd users. It's going to be all of our workers just asking AI to do things for them. We need to make sure we can provide an environment that supports that.

We need to prepare for the application life cycle to hypercompress, right? Instead of now where it might be planned for an hour, runs for 20 minutes, then it's gone again—that's one whole life cycle. Whatever we do for our policies, support, security, whatever we're building here has to also apply even if an application life cycle is only 4.5 seconds.

And finally, recognize the value shift. This ties back to the first one. The economics of applications are shifting, which means the value is shifting. The code is no longer valuable. The code is free. What's valuable is knowing what that code needs to do—the product manager side of things. I have this need for this worker. I've got this system and this data. I need it over here. It has to do this. Here's the guardrails. Here's the checks. Here's what you need. The value is in the definition of what needs to happen. The actual code—today it's Python, tomorrow it's Rust. The code that's generated has no value. What's valuable is what the code is specified to do. That's a big big change.

These are things that are all happening kind of near-term. For longer-term thinking, the things that are changing—apps were designed for humans. All the apps we have today are made for human consumption. That is not the case in the future. AI doesn't need access to apps. It doesn't need apps. It needs access to the data. It needs capabilities, tools to manipulate the data. But the AI does not need an application. Case in point, Claude basically created a version of Excel that runs in Claude against real Excel files. We don't need the app. They just need access to the data.

The traditional UI is going away. Apps are going to evolve from human-centric UIs today into AI-centric UIs. There's going to be older applications running on some remote Citrix server for the next 35 years on some little server in the corner that's never been rebooted and some process connects to it once a day using the HDX protocol maneuvering some old application. But that's going to be further and further the exception. When you have this environment of workers to AI to applications or workers to AI to your workspace, there's only one app—the AI platform—and that is showing everything else. Everything else is presented to the worker from there.

Context is the killer feature moving forward. Whoever masters this wins, right? The context of understanding what is trying to be done. I have this data and this data and this workspace and this identity and these security parameters and here's what I'm trying to do. Whether it's a one-shot where I can just have it done and move on or build a tool or write an application—understanding that context across devices, application profiles, data types—that's going to be the big key.

And the fourth one is it is going to transform from what I call application management—kind of what we're all doing today—to capabilities orchestration. We see this already. Look at these AI platforms and how many capabilities they have by using different tools and different models and stringing these together. It's understanding what capabilities the tools have that our workers are using and then how we need to constrain those and orchestrate those capabilities. So that's not just locking down, not just security and observability. It's also enabling these things to be used by our workers and to do what those workers need done. So we're not focusing on managing and securing applications. We're focusing on orchestrating the capabilities of the different tools that these workers are using.

So my final thoughts to walk away with on this—your job managing applications has an expiration date. It might be far enough in the future that that's okay. But the mindset of managing applications is going away. Now the good news is your skills in managing digital workspaces are more valuable than ever. Context matters. Understanding what the worker wants, what tools are using, where do these tools run, how do they operate, how does all the infrastructure work, how does all the security work—all of that is very, very important and this is going to be very valuable for us.

There is a crisis in the working world right now about younger workers coming up into corporations and how that's trained. There's a lot of big issues in that world. Our issues are different though. Those of us sitting in our room—we have expertise in certain areas. We will continue to have value by understanding that all these AIs that are created, all these applications that are created, they have to run somewhere and they have to be secured somewhere. For me the big change going forward is just a mindset. Start thinking about capabilities not about applications.

And the final thought I'd like to say to all the talks—this is happening whether you like it or not. It doesn't matter what you think. This is happening. The technical capabilities of ChatGPT and these platforms are mind-blowing. Every few weeks they release new capabilities. Every few weeks benchmarks are crushed. It's like almost once a quarter something that was going to maybe be fixed in 18 months or solved in 18 months is now solved today and it happens in two months instead of 18 months. It is mind-blowing. These changes are happening whether we like it or not.

Anyway, that's kind of my map. The final thing I have is just some links. You can follow me on LinkedIn. I blog about this stuff. I have a website at bmad.ai. It's like a short version of my name. There's no content there really—all my blogs are on Citrix—but on bmad.ai I have links to talks and blog posts and stuff like that. That's out there to find. So anyway, every day I'm writing and thinking about this kind of stuff. I'm reinvigorated about end user computing. It's like so fascinating now because of this technology. It's like the most interesting point I think in my entire career of 31 years so far. It's very fun times ahead. It's very very interesting. I think there's a lot of work for us to do. But that's my quick view on where we're going with applications in the next five years. Thanks for your time.
