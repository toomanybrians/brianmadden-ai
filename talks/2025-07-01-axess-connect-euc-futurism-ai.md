---
title: "What's next for EUC? Brian Madden talks futurism in the age of AI"
date: "2025-07-01"
event: "Axess Connect podcast"
hosts: Kris Haynes, Stefan Stickley
format: Podcast guest appearance (Part 1 of 2)
recording: https://axess.systems/information-technology-news/whats-next-for-euc-brian-madden-talks-futurism-in-the-age-of-ai/
authority_level: 5
file_type: talk
tags: [ai-agents, computer-using-agents, 7-stage-roadmap, mcp, a2a, knowledge-work, workspace-as-control-plane, euc, ai-as-worker]
staleness_threshold: stable
---

# Axess Connect — What's next for EUC? Brian Madden talks futurism in the age of AI

## Episode details

**Context:** Brian's first appearance on the Axess Connect podcast, approximately five months into his Citrix futurist role. Joined by Stefan Stickley (Axess Systems' internal AI specialist). Part 1 of a two-part conversation covering the futurist role, the 7-stage roadmap, and why AI's real impact on EUC comes through existing workspaces, not new cloud-native infrastructure.

**Key arguments made:**

- The futurist role is a "scout"—living five years ahead, painting the picture of the future so product teams can set direction
- The 7-stage roadmap frames everything: from simple Q&A through computer-using agents to multi-agent orchestration
- LLMs gained real power when they got tools—the shift from outputting text to using text to give themselves instructions was "the unlock"
- MCP is a universal API interface connecting AI to tools, data, and other agents via plain English wrapped in JSON
- A2A (agent-to-agent) allows AI systems to communicate and complete transactions without human involvement
- Computer-using agents observe pixels and operate mouse/keyboard—AI enters EUC through existing workspaces
- The humanoid robot analogy: general-purpose AI workers need to use the same tools as human workers—"Make yourself about six feet tall. Give yourself some fingers and use the tools I already have."
- Any KVM job (keyboard, video, mouse) is in play for AI disruption
- AI as a worker, not just a tool: from IT's standpoint, not much difference between provisioning for a human worker and an AI worker
- The "any-any-any" strategy extends to "any worker"—AI workers alongside human and augmented human workers
- The real EUC story isn't AI in admin tools—it's AI entering the knowledge worker's world using the same applications, identities, and processes
- "I've been working 31 years and this is the most exciting time in this industry for sure."

> **Note:** This is a condensed transcript highlighting Brian's key arguments, not a verbatim word-for-word record. The full episode is ~30 minutes. Refer to the [original audio](https://axess.systems/information-technology-news/whats-next-for-euc-brian-madden-talks-futurism-in-the-age-of-ai/) for the complete discussion.

## Transcript

[Intro by Kris Haynes—Brian Madden and Stefan Stickley discussing how AI is moving past the chatbot stage into agents, self-prompting, MCP, and real workplace impact. Episode split into two parts.]

**On the futurist role:**

This is a dream job for me. My role at Citrix is really more like a scout—way, way out there. Most of my time is focused on what's happening five years ahead. I do not live within our product group. My role is to say, what is the world of end-user computing and work going to look like in five years? What's important in that world? And then how does Citrix fit into that?

**On the 7-stage roadmap:**

I was having all these conversations about the future of AI and work, and everyone was talking about different things in different phases. So I laid it out from when ChatGPT came out—how were we using it? Simple questions, get an answer. Then deeper use. Then AI agents looking at your browser—Microsoft just announced Copilot for Edge. Stage four is computer-using agents. Stage five is computer-using agents running in the cloud without you watching. Then AI orchestration.

**On tools as the unlock:**

LLMs were famously bad at symbolic reasoning—math, counting letters. What we saw was instead of trying to make the models do this in their token word brain, just give them access to Python and these tools. It's like human evolution—from critters running around to now they have tools. That little link from "they output smart text" to "they can use the output text to give themselves instructions to do things"—that was the unlock. And then click, click, click, onward we go.

**On MCP and A2A:**

An LLM by itself was kind of in a sandbox. A really smart person, but you're only talking to them. Two protocols came out: A2A, agent to agent—allows two LLMs to talk to each other. It's a more sophisticated version of those earlier memes where you had Copilot on one phone and ChatGPT on the other.

Then MCP, model context protocol. A universal API interface you can put on top of anything—data sources, databases, Box, Dropbox, GitHub. An agent connects to an MCP server: "Hello." "Hi, I am a file database. I have a bunch of files. What would you like to find today?" Wrapped in JSON and some formatting, but really just plain English to connect.

These models are growing like a network of experts instead of one giant model. The experts they talk to don't have to be within that same model—they can be in other models. Much like humans and communities of humans and tools, the AI models are following that same path.

**On the humanoid robot analogy:**

Why are humanoid robots shaped like humans? If you have a task worker robot, make it like the task—a robot arm, a Roomba, a checkout counter. These only do one thing. If you have a general-purpose worker, a knowledge worker, it has to look like a human so it can do everything. Make yourself about six feet tall, give yourself some fingers, and use the tools I already have.

Taking that into knowledge work: where do I work today? Mac laptop, Chrome, Google Workspace, Workday, emails, meetings, podcasts. We need the AI to come into that world and use the same tools that we use. This isn't about building a new AI process that talks to APIs in a black box in the cloud. That's like saying I'm going to take all my existing desktop applications and turn them into SaaS apps—that's been 25 years in progress.

**On AI as a worker:**

A human is a worker. We're getting to the point where AI is a worker. And from the IT standpoint, there's not much real difference. If I have a desktop or a workspace with all my apps and my identity and my context, an AI worker ought to be able to connect to that in the exact same way a human worker connects.

Our workers, who for my whole career were only humans, are no longer only humans. We have AI workers. We have human workers. We have augmented human workers. It's just another "any" in the any-any-any strategy we've been doing for 30 years—any device, any application, anywhere, any connection, now any worker.

**On what AI in EUC really means:**

Every product is going to have AI in it—that's just the latest technology iteration. Not what I care about. That's not fundamentally transforming knowledge work.

The real story: every single rank-and-file knowledge worker who sits at a cubicle and does TPS reports every day—they are now in play to be majorly disrupted. Any job that really is just done through a computer probably can be disrupted by AI. Not today, but it's in play now. And for AI to enter that world, it has to fit into that world the way it already exists.

I've been working 31 years and this is the most exciting time in this industry for sure.
