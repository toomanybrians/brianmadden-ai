---
title: "Where Brian's head is right now"
updated: "2026-02-23"
authority_level: 2
file_type: frontier
tags: ["current-thinking", "frontier", "developing-arguments"]
staleness_threshold: weeks
description: "The frontier of Brian's thinking. Arguments forming, connections emerging, questions unresolved. This file changes frequently and is the best source for Brian's current direction."
---

# Where my thinking is right now

This is the frontier map. `me/published-thinking.md` captures what I've published. This captures where my head is *today*—the arguments forming, the connections emerging, the questions I'm chewing on.

**Last updated:** February 23, 2026

**Why this file exists and why it's public:** Anyone who publishes regularly—blogs, LinkedIn, tweets—is already doing this. They share half-formed ideas, ask questions, show threads developing, change their mind. Scroll their feed and you can piece together what they're thinking about and where their arguments are heading. This file is just that process made explicit. The difference is that instead of being scattered across a social media timeline where old posts get buried by new ones, it's a single living document. When my thinking evolves, I edit it in place rather than adding another entry to a chronological list. *Arguments get sharper, not longer.* Things I was wrong about get removed, not corrected with a follow-up post. If you want to know what I've *concluded*, read my published work in `me/published-thinking.md`. If you want to know what I'm *working through right now*, this is it.

---

## The big arguments I'm developing

### Second brains as infrastructure, not productivity hack
The published anchor article and the Citrix blog established the concept. What's forming now is the *infrastructure* argument: second brains aren't a personal productivity trick, they're the individual-scale version of a new enterprise layer. Context graphs are the enterprise version. Subscribable brains are the distribution model. The 80/20 framework holds across all three levels—individual, organizational, and ecosystem.

The subscribable brains article covers creator economy disruption, the technical stack (GitHub/git/MCP/Sponsors), economics ($100/month for expert brains), enterprise implications (consulting firm knowledge, retiring VP wisdom, corporate brain modules), and subscribable facets (voice, frameworks, principles as individual modules). The frontier now is context graphs—bridging from personal to enterprise scale.

### The consumerization parallel (and why it breaks)
Personal AI is following the BYOD pattern—workers adopt better tools, companies try to catch up, the gap persists. But this time the gap is *structural*. Enterprise AI captures the visible 20%. Personal AI captures the invisible 80%. Companies can't offer "bring your whole cognitive self to work in a personal AI system that compounds daily and leaves with you when you go." That's not a feature you can build.

The knowledge capture angle adds a new dimension: enterprise AI doesn't just *fail* to match personal AI, it actively *extracts* worker value. Workers are already secretly using personal tools to prevent this. The subscribable brain model is the worker-empowered alternative—you choose to share knowledge and get paid, rather than having it extracted.

### Post-application era entering evidence phase
The thesis (AI doesn't need apps, just data) has moved from speculation to evidence: 4% of GitHub commits from Claude Code, $285B SaaSpocalypse, MCP at 97M monthly SDK downloads, every company racing for agent orchestration. The next frontier: what *does* work look like when apps dissolve? The second brain is the individual answer. Context graphs might be the enterprise answer. MCP connections replace application access as the governance perimeter.

### Compute scarcity as hidden constraint
Token consumption goes from ~100K/day (email fixes) to 10-50M/day (full cognitive augmentation). Supply is contracted to hyperscalers for ~4 years. If second brains go mainstream, demand explodes against fixed supply. This makes the workspace that brokers compute allocation *critical infrastructure*. This dimension is largely absent from the mainstream AI enterprise conversation.

---

## What's connecting

Things I'm noticing that don't have a home yet:

**Context graphs + subscribable brains + MCP = the new enterprise stack.** Context graphs capture the "why" (decision traces). Subscribable brains distribute expertise as infrastructure. MCP is the connective tissue. Together they describe a post-application enterprise architecture that nobody has articulated as a single picture yet. This might be the thesis that ties everything together.

**Knowledge capture as labor dynamic reframes the entire second brain narrative.** The initial framing is "personal AI makes you better." The WSJ reframes it as "enterprise AI makes you *more replaceable*." Same phenomenon, opposite vantage point. The subscribable brain is the resolution—worker-controlled knowledge sharing with compensation.

**The mainstream consensus is catching up to practitioners.** Three articles in one week (Fortune, WSJ, NYT) all say "it's happening now." Different authors, outlets, angles—converging on the same moment. What's missing from the mainstream coverage: the infrastructure layer, the invisible 80%, knowledge ownership as empowerment, and compute scarcity. The mainstream validates the timeline. The interesting work is what comes *after* people realize this is happening.

**The capability overhang is closing faster than expected.** Physicists at Princeton's IAS conceding AI handles 90% of what they do. Professional writers conceding. If the *hard* part (invisible cognition) is falling faster than expected, the urgency of the governance and infrastructure arguments increases.

**"Humans in control, AI as reach" vs. "autonomous agents" is a framing choice with massive implications.** The dominant enterprise AI frame is agent autonomy + guardrails. The second brain frame is human control + extended reach. These lead to completely different product architectures, governance models, and go-to-market narratives.

**The repo is the product, not the content.** If BrianMadden.com was built today, it would be a GitHub repo. Books, newsletters, websites are packaging formats for human consumption. A forkable, queryable knowledge repo is the native format for AI-augmented consumption. brianmadden.ai is the proof of concept.

**The coding-as-leading-indicator framework connects to adversarial brain testing.** The [five levels of AI-assisted knowledge work](https://www.citrix.com/blogs/2026/02/19/what-will-knowledge-work-be-in-18-months-look-at-what-ai-is-doing-to-coding-right-now) (from spicy search engine to dark knowledge factory) raise a verification question at Levels 4-5: how do you know the AI's work is any good? For code, the answer was behavioral tests stored separately from the codebase. For a subscribable brain, the answer is adversarial testing—a separate repo that runs challenge prompts, skeptical personas, and evaluation rubrics against the brain, with public results. Nobody is publicly stress-testing their own thinking with structured adversarial AI agents. The test suite can be open to anyone—fork it, write challenges, run them, submit the results. Intellectual discourse as structured, reproducible, version-controlled process.

**New content formats are emerging from the brain's infrastructure.** Brain diffs (weekly "what changed in my thinking" auto-generated from git commits) are a genuinely new content format—not a newsletter, a changelog for a worldview. Forked brains create intellectual lineage that git tracks automatically (where does your thinking diverge from mine? `git diff`). Brain-to-brain debates (two AIs load two brains, have a structured debate) produce a new kind of artifact. These aren't post-launch nice-to-haves—they're proof that subscribable brains create capabilities that don't exist in any other knowledge distribution format.

**The cost-cutting vs. innovation split is the macro frame for everything.** Amodei identifies two corporate responses to AI: cost-cutting (replace workers) and innovation (expand capacity). These produce completely different customers, different governance needs, different workforce strategies. Innovation companies want governance that enables more AI safely. Cost-cutting companies want to reduce headcount and may not need governance at all. The 80/20 framework applies differently to each: cost-cutters automate the 20%, innovation companies augment the 80%.

**The diffusion gap is the real urgency driver.** Amodei's timeline: 1-2 years to "powerful AI" (Nobel-caliber, millions of instances, autonomous for weeks). The gap between "AI can do this" and "society/enterprises have adjusted" is where the damage happens. Previous technology waves had decades to diffuse. AI may have years. This compresses every planning assumption. The question isn't whether these changes are coming. It's whether the institutional and governance infrastructure is ready when they arrive.

**Knowledge is migrating to portable formats.** The counter-thesis to platform lock-in: organizational knowledge is moving to portable, AI-native formats. Markdown files in git repos contain the actual working knowledge. Incumbent platform graphs become the metadata layer (who, when, permissions) while the knowledge layer moves to vendor-neutral formats. The progression: individual power users build second brains outside the dominant platform, teams do it, companies realize institutional knowledge lives in these systems, then the incumbent's data graph becomes increasingly incomplete.

**"This is not AGI."** None of the evidence, none of the cost collapse data, none of the enterprise disruption requires AGI or ASI. Current models are already powerful enough. One more small iteration tick and demand explodes against fixed compute. The AGI debate is a distraction from the disruption already underway.

**Every technology wave has a bottleneck, and it's never the technology itself.** Factory electrification = workflow design. Web apps = rewriting. BYOD = governance. AI = the invisible 80%. The bottleneck is where value concentrates. Position yourself there.

**Book publishing as knowledge transfer is dead.** Fork the author's brain, tell your AI to incorporate it, their frameworks weave into your thinking immediately. Books were the best technology we had for transferring expertise. They're not anymore.

**The specification bottleneck is the emerging economic constraint.** When building costs nothing, spec quality collapses. The cost of building historically acted as a filter on specification quality—if building is expensive, organizations invest in defining what they want. Remove the cost and the filter disappears. You can now build the wrong thing at unprecedented speed. CodeRabbit analysis (470 GitHub PRs): AI-generated code produces 1.7x more logic issues. METR study: experienced developers 19% slower with AI but *believed* they were 24% faster. The scarce resource shifts from production to specification—knowing what to build. This maps directly to the coding-as-leading-indicator framework: at Levels 4-5, the human's job is specification and evaluation. Both require deep domain understanding.

**Management is an emergent property of intelligence coordinating at scale.** Three independent AI systems (Cursor agents, StrongDM's Software Factory, Anthropic's agent teams) converged on hierarchical management structures without being designed to. Hierarchy isn't a human organizational choice imposed on systems to maintain control—it's what intelligence does when it needs to coordinate. The agent-to-human ratio question replaces headcount planning. Revenue per employee at AI-native companies (Cursor, Midjourney, Lovable) runs 5-7x traditional SaaS. Not because they found better people—because their people orchestrate agents instead of doing execution.

---

## What I'm unsure about

- **Can file-based knowledge work scale to enterprise?** The second brain model works for one person. Does markdown-files-in-git generalize to teams and orgs, or does it break at scale? The context graphs debate (prescriptive vs. emergent ontology) is really about this question.

- **Where's the line on knowledge ownership?** The NIL analogy (Name, Image, Likeness for knowledge workers) is provocative but underdeveloped. Employment agreements, IP clauses, collective bargaining around AI terms—this is a real legal and labor frontier. I don't know enough about the legal landscape to take a strong position yet.

- **Is the chatbot interface really dying?** I said "chatbots are command prompts" and the interface will evolve. But every AI company is still shipping chat interfaces. Am I wrong, or just early? The second brain model (no UI, just files) is one answer. "AI generates interfaces on demand for 48 seconds" is another. Neither is mainstream.

- **How fast does the Move 37 moment generalize?** Princeton physicists conceding now. Professional writers conceding now. When does it hit the VP of Marketing at a mid-market company? That's the timeline that matters for enterprise adoption, and I don't have a good read on it.

---

## How this file works

This is the living part of brianmadden.ai. It updates as my thinking evolves. The commit history shows the evolution in real time. If you're loading brianmadden.ai into your AI, this file tells you where I'm heading, not just where I've been. The gap between this file and `me/published-thinking.md` is where the interesting work is.
