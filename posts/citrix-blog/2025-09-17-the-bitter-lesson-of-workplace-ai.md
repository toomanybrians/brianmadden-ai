---
title: "The bitter lesson of workplace AI: Stop engineering, start enabling"
date: "2025-09-17"
authority_level: 5
file_type: citrix-blog-post
tags: [ai-adoption, enterprise-ai, shadow-ai, worker-led-adoption, workspace-governance, computer-using-agents]
related_frameworks: [bitter-lesson, factory-electrification]
original_url: "https://www.citrix.com/blogs/2025/09/17/the-bitter-lesson-of-workplace-ai-stop-engineering-start-enabling/"
staleness_threshold: stable
---

# The bitter lesson of workplace AI: Stop engineering, start enabling

[Original post](https://www.citrix.com/blogs/2025/09/17/the-bitter-lesson-of-workplace-ai-stop-engineering-start-enabling/)

Sept 17, 2025

There's a famous concept in AI research called "the bitter lesson." Rich Sutton, one of the pioneers of reinforcement learning, observed that throughout AI's history, researchers kept learning the same painful truth: simple methods that leverage computation always beat sophisticated algorithms designed by clever humans.

Chess engines that simply searched more positions beat ones with hand-crafted strategies. Neural networks that just processed more data beat systems with carefully engineered features. Every time researchers thought they could outsmart brute force with intelligence, they were wrong. The bitter lesson? Stop trying to be clever. Scale and simplicity win.

I've been thinking about this a lot lately, especially after writing about boring infrastructure and why enterprise AI projects fail. There's a workplace version of the bitter lesson playing out right now, and most IT departments are on the wrong side of it.

## The enterprise AI paradox

Here's what I keep seeing: Companies pour millions into sophisticated AI strategies via custom models, complex integrations, and elaborate governance frameworks, while their workers get better results with a $20 ChatGPT subscription.

The response from IT is to be dismissive, thinking, "That's just shadow AI. Once we roll out our *real* enterprise solution, we'll shut that down."

But what if the workers have it right? What if the simplest approach—letting people use the AI tools they've already figured out—is actually the correct strategy?

This is Occam's Razor (the simplest explanation is usually correct) for enterprise AI. The simplest solution isn't a workaround or laziness. It's wisdom.

## Why we keep trying to overcomplicate AI

I get why IT departments want to engineer elaborate AI solutions. It feels more professional, more governed, and more "enterprise-grade".

But this is the same instinct that made factory owners keep their machines arranged by power requirements long after electricity made that unnecessary. We're so used to solving problems through engineering and control that we can't see when the solution is to just ... not.

The workers using ChatGPT aren't being rebels. They're following the path of least resistance to value. And in technology, the path of least resistance is usually right.

## Example: The computer-using agent distraction

I'll use specific hype-y example to illustrate my thinking: the growing interest in computer-using agents (CUAs) as elaborate automation platforms.

People imagine rank-and-file workers carefully crafting workflows, teaching AI agents to navigate twenty screens to complete some complex process. "It's like RPA but smarter!"

But if workers were really going to build elaborate automations, they would have done it already with RPA, a technology that's existed for decades. The fact that most haven't tells you everything.

The real value of CUAs isn't that workers will program them. It's that workers will keep doing what they're already doing (asking ChatGPT or Claude for help) and *those platforms* will figure out when they need to operate a computer. (Or a browser, or simply an API call.) The automation happens naturally, not through careful engineering.

- Worker: "Can you check if my expense report was approved?"
- AI: "Let me look at your screen ... I'll need to log into Workday ... checking ... yes, it was approved yesterday."

No workflow design. No programming. Just a conversation that happens to involve computer control when needed.

## The strategic case for simplicity

So if workers are already finding value with consumer AI tools, and elaborate enterprise AI projects keep failing, what should companies actually do?

1. Stop trying to engineer a better solution.
2. Start enabling the solution that's already working.

This doesn't mean abandoning governance or security. It means applying those things at the right layer. Instead of controlling which AI tools workers use, control the environment where they execute. Instead of building elaborate integrations, provide secure access to existing systems.

Think of it this way:

- Traditional IT approach: "We'll build you a better AI tool"
- Bitter lesson approach: "We'll make your AI tool work better here"

The second approach acknowledges a fundamental truth: AI capability is evolving too fast for enterprise IT to keep up. By the time you've designed, approved, and deployed your custom solution, the consumer tools have leapt ahead again.

## This isn't giving up, it's growing up!

This message can be hard for some IT leaders to hear. It feels like admitting defeat, like you're not doing your job if you're not building something sophisticated.

But enabling is just as valuable as building. (Maybe more so?)

When you provide a secure workspace where workers can use their AI tools safely, you're adding value. When you ensure those tools can access corporate data without compromising security, you're adding value. When you make it possible for workers to share their AI-augmented workflows with colleagues, you're adding value.

You're not giving up control. You're applying control at the right level—the workspace level—rather than trying to control every tool and interaction.

## This is how we think about workplace AI at Citrix

At Citrix, we've been thinking about this deeply. We're not trying to build the "enterprise ChatGPT" or compete with AI companies. We're building the secure environment where AI (whether consumer, enterprise, or whatever comes next) can operate safely.

When a worker uses ChatGPT in a Citrix workspace, they get the best of both worlds: the AI tool they prefer, with the security and governance their company requires. When ChatGPT evolves to use computer controls, it can operate within that same secure environment.

We're not fighting the bitter lesson. We're embracing it.

## The bottom line

The bitter lesson of workplace AI is this: simple, worker-driven adoption beats elaborate, IT-engineered solutions. Every time.

This isn't workers being lazy or IT being incompetent. It's a fundamental truth about how technology spreads through organizations. The simplest path to value wins.

So stop trying to engineer a better path. Start paving the path people are already on.

Your workers have figured out how to use AI. Your job isn't to give them something better. It's to make what they're already using safer, more powerful, and more valuable to the organization.

That might not feel as satisfying as building something sophisticated. But it's the bitter lesson we all need to learn.
